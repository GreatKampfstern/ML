{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programm zur Erkennung von Hunderassen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 1: Daten laden und Aufteilen in Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren der notwendigen Bibliotheken\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "from skimage import io, transform\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import copy\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_to_split(dataset_path, annotation_path):\n",
    "    # Funktion zum Parsen der Annotationsdateien\n",
    "    def parse_annotation(xml_file):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        bndboxes = []\n",
    "        for obj in root.findall('object'):\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = int(float(bndbox.find('xmin').text))\n",
    "            ymin = int(float(bndbox.find('ymin').text))\n",
    "            xmax = int(float(bndbox.find('xmax').text))\n",
    "            ymax = int(float(bndbox.find('ymax').text))\n",
    "            bndboxes.append((xmin, ymin, xmax, ymax))\n",
    "        return bndboxes\n",
    "\n",
    "    # Laden der Bilder und Extrahieren der Hundebereiche\n",
    "    images = []\n",
    "    labels = []\n",
    "    breeds = os.listdir(dataset_path)\n",
    "\n",
    "    for breed in breeds:\n",
    "        breed_img_path = os.path.join(dataset_path, breed)\n",
    "        breed_anno_path = os.path.join(annotation_path, breed)\n",
    "        if os.path.isdir(breed_img_path):\n",
    "            for img_name in os.listdir(breed_img_path):\n",
    "                img_path = os.path.join(breed_img_path, img_name)\n",
    "                annotation_name = os.path.splitext(img_name)[0]\n",
    "                annotation_file = os.path.join(breed_anno_path, annotation_name)\n",
    "                if not os.path.exists(annotation_file):\n",
    "                    continue  # Überspringe Bilder ohne Annotation\n",
    "                image = io.imread(img_path)\n",
    "                if image is None:\n",
    "                    continue\n",
    "                bndboxes = parse_annotation(annotation_file)\n",
    "                for bndbox in bndboxes:\n",
    "                    xmin, ymin, xmax, ymax = bndbox\n",
    "                    xmin = max(0, xmin)\n",
    "                    ymin = max(0, ymin)\n",
    "                    xmax = min(image.shape[1], xmax)\n",
    "                    ymax = min(image.shape[0], ymax)\n",
    "                    if xmin >= xmax or ymin >= ymax:\n",
    "                        continue  # Ungültige Bounding Box überspringen\n",
    "                    cropped_image = image[ymin:ymax, xmin:xmax]\n",
    "                    cropped_image = transform.resize(cropped_image, (256, 256))\n",
    "                    images.append(cropped_image)\n",
    "                    labels.append(breed)\n",
    "\n",
    "    # Umwandeln der Labels in numerische Werte\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(labels)\n",
    "\n",
    "    # Überprüfen, ob Bilder geladen wurden\n",
    "    if len(images) == 0:\n",
    "        print(\"Fehler: Keine Bilder geladen. Bitte überprüfen Sie den Pfad und die Annotationsdateien.\")\n",
    "\n",
    "    return np.array(images), y, le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier werden die Daten initial eingelesen, \"le\" ist dabei der LabelEncoder um die Labels später wieder zu den ursprünglichen Namen zu ändern\n",
    "X, y, le = read_images_to_split(\"dogs\", \"annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Schritt: Netzarchitektur festlegen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNNs) eignen sich hervorragend für Bildklassifikationsaufgaben, da sie räumliche Strukturen in Bildern effektiv erkennen können. CNNs verwenden Faltungsoperationen, die es ihnen ermöglichen, lokale Merkmale wie Kanten, Texturen und Formen zu extrahieren, die für die Unterscheidung von Hunderassen essenziell sind.\n",
    "\n",
    "**Gründe für die Wahl von CNNs:**\n",
    "\n",
    "1. Parameterreduzierung: Durch Gewichtsteilung reduzieren CNNs die Anzahl der zu lernenden Parameter im Vergleich zu vollständig verbundenen Netzwerken. Dies ist insbesondere bei großen Eingabebildern (z. B. 256x256) wichtig.\n",
    "2. Translation Invariance: CNNs können wichtige Merkmale unabhängig von deren Position im Bild erkennen, was bei der Hunderassenerkennung hilfreich ist, da die Hunde in unterschiedlichen Posen und Perspektiven dargestellt sein können.\n",
    "3. Hierarchisches Lernen: CNNs lernen in den unteren Schichten einfache Merkmale (wie Kanten) und kombinieren diese in höheren Schichten zu komplexeren Merkmalen (z. B. Gesichtszüge von Hunden).\n",
    "\n",
    "**Netzwerkarchitektur:**\n",
    "Für die Hunderassenerkennung wähle ich folgende Architektur:\n",
    "\n",
    "- *Eingabeschicht*: Input-Shape (256, 256, 3) (RGB-Bilder mit Größe 256x256).\n",
    "- *Faltungsschichten (Convolutional Layers)*: Mehrere Schichten mit 3x3-Filtern und zunehmender Filteranzahl (z. B. 32, 64, 128), um unterschiedliche Merkmale zu extrahieren.\n",
    "- *Pooling-Schichten (MaxPooling)*: Nach jeder Faltungsschicht zur Reduktion der räumlichen Dimension und zur Verhinderung von Überanpassung.\n",
    "- *Batch-Normalisierung*: Um die Trainingsstabilität zu erhöhen und den Gradientenfluss zu verbessern.\n",
    "- *Dropout*: Nach den Faltungsblöcken, um Überanpassung zu reduzieren.\n",
    "- *Fully-Connected Layer*: Eine oder mehrere vollständig verbundene Schichten, um die gelernte Merkmalsrepräsentation in Klassen zu übersetzen.\n",
    "- *Ausgabeschicht*: Softmax-Aktivierung mit so vielen Neuronen wie Hunderassenklassen.\n",
    "\n",
    "Deswegen wurde nach der Input Schicht jeweils drei mal ein Convolutional Layer, gefolgt von einem MaxPooling Layer, Batch Normalization und einem Dropout Layer verwendet. \n",
    "Somit wir nach und nach erst mit der Convolutional Layer die Merkmale des Bildes extrahiert, dann mit dem MaxPooling Layer die Dimensionalität reduziert, mit der Batch Normalization die Trainingsstabilität erhöht und mit dem Dropout Layer die Überanpassung reduziert.\n",
    "Am Ende wird die Flatten Schicht verwendet, um die Daten in ein Format zu bringen, welches von den Fully Connected Layern verarbeitet werden kann.\n",
    "Die Ausgabeschicht hat 5 Neuronen, da es 5 Hunderassenklassen gibt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Schritt: Netzarchitektur implementieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netzwerkarchitektur\n",
    "model = Sequential([\n",
    "    # Input layer\n",
    "    Input(shape=(256, 256, 3)),\n",
    "    \n",
    "    # Faltungsschicht 1\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    # Add other layers as needed\n",
    "\n",
    "    # Faltungsschicht 2\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    # Faltungsschicht 3\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    # Übergang zu Fully-Connected Layers\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    # Ausgabeschicht\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "# Netzwerkübersicht anzeigen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Schritt: Wahl einer geeigneten Lossfunktion und eines Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss-Funktion:** CategoricalCrossentropy <br>\n",
    "Diese Funktion eignet sich für Multi-Klassen-Klassifikationsprobleme und misst die Divergenz zwischen den vorhergesagten Wahrscheinlichkeiten und den tatsächlichen Klassenlabels.\n",
    "\n",
    "**Optimizer:** Adam <br>\n",
    "Der Adam-Optimizer kombiniert die Vorteile von AdaGrad und RMSProp und passt die Lernrate für jeden Parameter dynamisch an. Er ist robust und effizient, besonders bei großen Datenmengen und komplexen Modellen. <br>\n",
    "<sup>(Quelle: Vorlesung)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kompilierung des Modells\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001), # Die Learning Rate wird hier zur Standard Rate gesetzt um später den Unterschied besser sichtbar zu machen\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation mit der Kreuzvalidierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',         # Zu überwachende Metrik\n",
    "    patience=5,                 # Anzahl der Epochen ohne Verbesserung, bevor das Training gestoppt wird\n",
    "    restore_best_weights=True   # Beste Gewichte automatisch wiederherstellen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kreuzvalidierung (3-fold)\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "conf_matrices = []\n",
    "histories = []\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X, y):\n",
    "    print(f\"Fold {fold} am Laufen\")\n",
    "    X_train_fold, X_val_fold =X[train_idx], X[val_idx]\n",
    "    y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "    # One Hot Encoden der Daten\n",
    "    y_train_fold = to_categorical(y_train_fold, num_classes=5)\n",
    "    y_val_fold = to_categorical(y_val_fold, num_classes=5)\n",
    "    \n",
    "    # Training\n",
    "    model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold),\n",
    "              epochs=50, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Vorhersage mit dem in diesem Fold trainiertem Modell\n",
    "    y_pred = model.predict(X_val_fold)\n",
    "\n",
    "    # Konvertieren der Werte, damit sie später ausgelesen werden können\n",
    "    y_val_int = np.argmax(y_val_fold, axis=1)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Speichern der Labels für den Report\n",
    "    all_y_true.extend(y_val_int)\n",
    "    all_y_pred.extend(y_pred_classes)\n",
    "\n",
    "    \n",
    "    # Speichern der Konfusionsmatrix\n",
    "    conf_matrices.append(confusion_matrix(y_val_int, y_pred_classes))\n",
    "    fold += 1\n",
    "\n",
    "\n",
    "# Klassifizierungsbericht\n",
    "print(\"\\nKlassifizierungsbericht (Gesamtergebnis aus allen Folds):\\n\")\n",
    "print(classification_report(all_y_true, all_y_pred, target_names=le.classes_))\n",
    "\n",
    "# Mittelwert der Konfusionsmatrizen berechnen\n",
    "avg_conf_matrix = np.mean(conf_matrices, axis=0)\n",
    "\n",
    "# Visualisierung der Konfusionsmatrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=avg_conf_matrix, display_labels=le.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=90)\n",
    "plt.title(\"Durchschnittliche Konfusionsmatrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Aufgabe 5 \n",
    "\n",
    "#### Precision\n",
    "Precision misst den Anteil der korrekt als positiv klassifizierten Instanzen an allen als positiv klassifizierten Instanzen. In diesem Bericht variieren die Precision-Werte zwischen 0.59 und 0.78, was bedeutet, dass zwischen 59% und 78% der als jeweilige Hunderasse vorhergesagten Instanzen tatsächlich korrekt waren.\n",
    "\n",
    "#### Recall\n",
    "Recall misst den Anteil der korrekt als positiv klassifizierten Instanzen an allen tatsächlich positiven Instanzen. Hier liegen die Recall-Werte zwischen 0.53 und 0.89, was zeigt, dass das Modell zwischen 53% und 89% der tatsächlichen positiven Instanzen korrekt erkannt hat.\n",
    "\n",
    "##### F1-Score\n",
    "Der F1-Score ist der harmonische Mittelwert von Precision und Recall und dient als Maß für die Balance zwischen diesen beiden Metriken. In diesem Klassifikationsreport variieren die F1-Scores zwischen 0.63 und 0.83. Ein höherer F1-Score deutet darauf hin, dass das Modell sowohl in der Genauigkeit als auch in der Erkennungsrate gut abschneidet. Hier zeigt der F1-Score, dass das Modell insgesamt eine ausgewogene Leistung erbringt, indem es sowohl falsche positive als auch falsche negative Vorhersagen minimiert. Zum Beispiel, der Maltese Dog hat den höchsten F1-Score von 0.83, was bedeutet, dass das Modell für diese Klasse besonders gut funktioniert, während der Greater Swiss Mountain Dog mit einem F1-Score von 0.63 schlechter abschneidet, was in diesem Fall an dem schlechten Recall-Wert dieser Klasse liegt.\n",
    "\n",
    "#### Zusammenfassung\n",
    "Zusammengefasst zeigt das CNN-Modell solide Leistungen bei der Klassifikation der fünf Hunderassen mit einer durchschnittlichen Genauigkeit von 0,71, was deutlich über zufälligem Raten (20%) liegt, womit das Trainieren des Modells als Erfolg gewertet werden kann. Dass Schipperke und Greater Mountain Dog schlechter abschneiden, liegt vor allem daran, dass es weniger Bilder von diesen gibt, das Gegenteil gilt für den Maltese Dog, der die meisten Bilder hat und deshalb am besten abschneidet. \n",
    "\n",
    "Deshalb wäre ein Ansatz  die Genauigkeit zu erhöhen, dass man Rassen mit gleich vielen Bildern wählt. Man könnte auch den ähnlichen Ansatz der Data Augmentation wählen, um eine gleiche Anzahl von Daten pro Rasse zu schaffen.\n",
    "Eine weitere Möglichkeit ist die generelle Erhöhung des Datensatzes, zum Beispiel durch externe Quellen, dies würde auch ermöglichen, dass man die Daten besser evaluieren kann und das momentane Ergebnis entweder bestätigen oder widerlegen kann.\n",
    "Auch wäre natürlich eine Anpassung der Modellarchitektur möglich, um zum Beispiel mehr Hunderassen zu erkennen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainieren des (alten) Modells mit allen Daten, damit es für Transfer Learning genutzt werden kann\n",
    "y_hot_enc = to_categorical(y, num_classes=5)\n",
    "model.fit(X, y_hot_enc, epochs=30, batch_size=32, verbose=0, callbacks=[early_stopping], validation_data=(X, y_hot_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methode um den Verlauf des Trainings zu visualisieren\n",
    "def visualize_history(history):\n",
    "\n",
    "    # Loss-Werte\n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "\n",
    "    # Accuracy-Werte (falls verwendet)\n",
    "    accuracy = history.get('accuracy')\n",
    "    val_accuracy = history.get('val_accuracy')\n",
    "\n",
    "    # Epochen erstellen\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    # Plot für den Loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, 'bo-', label='Trainings Loss')\n",
    "    plt.plot(epochs, val_loss, 'ro-', label='Validierungs Loss')\n",
    "    plt.title('Trainings und Validierungs Loss')\n",
    "    plt.xlabel('Epochen')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot für die Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, 'bo-', label='Trainings Genauigkeit')\n",
    "    plt.plot(epochs, val_accuracy, 'ro-', label='Validierungs Genauigkeit')\n",
    "    plt.title('Trainings und Validierungs Genauigkeit')\n",
    "    plt.xlabel('Epochen')\n",
    "    plt.ylabel('Genauigkeit')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entfernen der letzten drei Schichten und Hinzufügen neuer Schichten\n",
    "\n",
    "new_model = copy.deepcopy(model)\n",
    "\n",
    "new_model.pop()\n",
    "new_model.pop()\n",
    "new_model.pop()\n",
    "\n",
    "# Hinzufügen neuer Schichten\n",
    "new_model.add(Dense(256, activation='relu'))\n",
    "new_model.add(Dropout(0.5))\n",
    "new_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "# Gefrorene Schichten (bis zur neuen Dense-Schicht)\n",
    "for layer in new_model.layers[:-3]:  # Alle außer den neuen Schichten einfrieren\n",
    "    layer.trainable = False\n",
    "\n",
    "# Kompilieren des neuen Modells\n",
    "new_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Überblick über das neue Modell\n",
    "#new_model.summary()\n",
    "\n",
    "# \n",
    "X_new, y_new, le_new = read_images_to_split(\"dogs_extended\", \"annotations\")\n",
    "X_train_new, X_test_new, y_train_new_spl, y_test_new_spl = train_test_split(X_new, y_new, test_size=0.25, stratify=y_new, random_state=42)\n",
    "\n",
    "# One hot Encoden der Daten\n",
    "y_train_new = to_categorical(y_train_new_spl, num_classes=5)\n",
    "y_test_new = to_categorical(y_test_new_spl, num_classes=5)\n",
    "\n",
    "print(\"Trainieren der neuen Ausgabeschicht\")\n",
    "# Training der neuen Ausgabeschicht\n",
    "history = new_model.fit(\n",
    "    X_train_new, y_train_new,\n",
    "    validation_data=(X_test_new, y_test_new),\n",
    "    epochs=30, batch_size=16, verbose=1\n",
    ")\n",
    "\n",
    "# Feinabstimmung des gesamten Modells\n",
    "for layer in new_model.layers:\n",
    "    layer.trainable = True  # Alle Schichten freigeben\n",
    "\n",
    "# Reduzierte Lernrate für Fine-Tuning\n",
    "new_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"Finetuning des gesamten Modells\")\n",
    "history_finetune  = new_model.fit(\n",
    "    X_train_new, y_train_new,\n",
    "    validation_data=(X_test_new, y_test_new),\n",
    "    epochs=5, batch_size=16, verbose=1\n",
    ")\n",
    "\n",
    "# Kombinieren der Trainingsergebnisse, damit das Trainieren der letzten Ebenenen, sowie das Feintuning in einem Graph visualisiert wird\n",
    "for key in history.history.keys():\n",
    "    history.history[key].extend(history_finetune.history[key])\n",
    "\n",
    "visualize_history(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen für Testdaten\n",
    "y_pred_new = new_model.predict(X_test_new)\n",
    "\n",
    "# Konvertiere die Vorhersagen zu Klassenindizes\n",
    "y_pred_classes_new = np.argmax(y_pred_new, axis=1)\n",
    "y_test_int_new = np.argmax(y_test_new, axis=1)\n",
    "\n",
    "# Konfusionsmatrix\n",
    "conf_matrix_new = confusion_matrix(y_test_int_new, y_pred_classes_new)\n",
    "disp_new = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_new, display_labels=le_new.classes_)\n",
    "disp_new.plot(cmap=plt.cm.Blues, xticks_rotation=90)\n",
    "plt.title(\"Konfusionsmatrix - Transfer Learning\")\n",
    "\n",
    "#y_pred_classes_new = to_categorical(y_pred_classes_new)\n",
    "\n",
    "#y_pred_classes_new = to_categorical(y_pred_classes_new)\n",
    "report = classification_report(y_test_int_new, y_pred_classes_new, target_names=le_new.classes_)\n",
    "\n",
    "print(report)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Aufgabe 6\n",
    "\n",
    "Das Modell aus Aufgabe 5 wurde kopiert, die letzten 3 Schichten entfernt (da die Schichten davor für die Feature Extraction sind) und dann wurden drei neue Schichten hinzugefügt, welche danach mit den neuen Daten trainiert wurden, um die Zuordnung der Features zu den Klassen neu festzulegen. Danach wurde noch ein Finetuning auf das gesamte Modell angewandt.\\\n",
    "Trotz dessen hat das neue Modell mit den neuen Hunderassen eine schlechtere Genauigkeit (0,68(neues Modell) zu 0,71(altes Modell)), dieser Unterschied wäre eigentlich noch stärker, da bei diesem Modell die ausgewählten Hunderassen ungefähr gleich viele Bilder haben (was ja bei Aufgabe 5 nicht der Fall war).\n",
    "\n",
    "Der Grund warum dieses Modell trotzdem schlechter abschneidet ist vermutlich unter anderem, weil die Feature Exraction auf die Hunde des ersten Modells angepasst ist. (nenne weitere Gründe)\\\n",
    "Auch könnte es sein, dass die neuen Hunderassen schwieriger zu erkennen sind, als die alten, was auch zu einer schlechteren Genauigkeit führen könnte, was dadurch zu beheben wäre die neuen Hunderassen nochmal genauer von den möglichen Merkmalen zu untersuchen und dann entsprechend unterschiedliche Rassen zu wählen, die sich in den Merkmalen stark unterscheiden.\\\n",
    "Eine weitere Möglichkeit warum dieses neue Modell schlechter abschneidet, wäre, dass die Bilder der neuen Hunderassen schlechter sind, als die der alten, also zum Beispiel die Hunde und deren Merkmale auf den Bildern nicht so gut herauskommen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
